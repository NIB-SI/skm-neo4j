{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import neo4j DB: 4/?\n",
    "\n",
    "Code to translate v2.7.4_PIS-model.xlsx to neo4j database. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import Image\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph, Node, Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to graph via docker-compose link. See http://localhost:7474/browser/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph(host=\"neo4j\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "base_path = Path(\"..\")\n",
    "parsed_path = base_path / \"data\" / \"parsed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_species = ['ath', 'osa', 'stu', 'sly']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reactions sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges = pd.read_csv(parsed_path / \"edges-sheet.tsv\", sep=\"\\t\", index_col=0)\n",
    "df_edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_functional_clusters = pd.read_csv(parsed_path / \"functional_clusters.tsv\", sep=\"\\t\")\n",
    "translate_functional_clusters = translate_functional_clusters.set_index(['node_name', 'level', 'species'])\n",
    "translate_functional_clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_list(subdf, ids, new_name, homologues=True):\n",
    "    col_suffixes = ['_newID', '_location', '_label', '_form']\n",
    "    new_col_suffixes = ['_name', '_location', '_label', '_form']\n",
    "\n",
    "    if homologues:\n",
    "        col_suffixes += homologue_cols\n",
    "        new_col_suffixes += homologue_cols\n",
    "        \n",
    "    for old_suf, new_suf in zip(col_suffixes, new_col_suffixes):\n",
    "        new_col = new_name + new_suf\n",
    "        old_cols = [id_ + old_suf for id_ in ids]\n",
    "        subdf[new_col] = subdf[old_cols].apply(lambda x: [i for i in x.values], axis=1)\n",
    "        \n",
    "        \n",
    "def rename_target(subdf, id_, new_name, homologues=True):\n",
    "    col_suffixes = ['_newID', '_location', '_label', '_form']\n",
    "    new_col_suffixes = ['_name', '_location', '_label', '_form']\n",
    "\n",
    "    if homologues:\n",
    "        col_suffixes += homologue_cols\n",
    "        new_col_suffixes += homologue_cols\n",
    "\n",
    "    for old_suf, new_suf in zip(col_suffixes, new_col_suffixes):\n",
    "        new_col = new_name + new_suf\n",
    "        old_col = id_ + old_suf\n",
    "        subdf[new_col] = subdf[old_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_nodes(df, x):\n",
    "    rows_with_x = set()\n",
    "    for i, row in df.iterrows():\n",
    "        for col_prefix in ['input1', 'input2', 'input3', 'output1']:\n",
    "            if row[col_prefix + \"_ID\"] in x:\n",
    "                rows_with_x.add(i)\n",
    "    return rows_with_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_input_different(df, homologues=True, catalyst=False):\n",
    "    ''' If catalyst is True, it is the last \"input\" col. '''\n",
    "\n",
    "    if catalyst:\n",
    "        # two inputs, input2 -> catalyst\n",
    "        subdf2 = df[df[\"input3_newID\"].isna()].copy()\n",
    "        generate_list(subdf2, ['input1'], 'substrate', homologues=homologues)\n",
    "        rename_target(subdf2, 'input2', 'catalyst', homologues=homologues)\n",
    "\n",
    "        # three inputs, input3 -> catalyst\n",
    "        subdf3 = df[~df[\"input3_newID\"].isna()].copy()\n",
    "        generate_list(subdf3, ['input1', 'input2'], 'substrate', homologues=homologues)        \n",
    "        rename_target(subdf3, 'input3', 'catalyst', homologues=homologues)\n",
    "        \n",
    "    else:\n",
    "        # two inputs\n",
    "        subdf2 = df[df[\"input3_newID\"].isna()].copy()\n",
    "        generate_list(subdf2, ['input1', 'input2'], 'substrate', homologues=homologues)\n",
    "\n",
    "        # three inputs\n",
    "        subdf3 = df[~df[\"input3_newID\"].isna()].copy()\n",
    "        generate_list(subdf3, ['input1', 'input2', 'input3'], 'substrate', homologues=homologues)\n",
    "    \n",
    "    # combine\n",
    "    new_subdf = subdf2.append(subdf3)\n",
    "    rename_target(new_subdf, 'output1', 'product', homologues=homologues)\n",
    "    \n",
    "    return new_subdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcription genes\n",
    "substrate_cols_wo_homologues = ['substrate_name', 'substrate_form', 'substrate_label', 'substrate_location']\n",
    "product_cols_wo_homologues = ['product_name', 'product_form', 'product_label',  'product_location']\n",
    "catalyst_cols_wo_homologues = ['catalyst_name', 'catalyst_form', 'catalyst_label', 'catalyst_location']\n",
    "\n",
    "# homologue_cols = [f\"_{x}_homologues\" for x in all_species]\n",
    "\n",
    "substrate_cols = [ f'substrate{x}' for x in ['_name', '_label', '_form', '_location']] #+#\\\n",
    "               # [f\"substrate{x}\" for x in homologue_cols]\n",
    "catalyst_cols = [ f'catalyst{x}' for x in ['_name', '_label', '_form', '_location']] #+\\\n",
    "                #[f\"catalyst{x}\" for x in homologue_cols] \n",
    "product_cols = [ f'product{x}' for x in ['_name', '_label', '_form', '_location']] #+\\\n",
    "               # [f\"product{x}\" for x in homologue_cols]\n",
    "\n",
    "reaction_standard_columns = ['AddedBy', 'Species', \n",
    "       'AdditionalInfo',  'external_links', 'trust_level',\n",
    "       'ModelV', 'ReactionEffect', 'reaction_type', 'Modifications', 'reaction_id']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_dict(file):\n",
    "#     d = {}\n",
    "#     with open(file, \"r\") as f:\n",
    "#         for line in f:\n",
    "#             key, value = line.strip().split(\"\\t\")\n",
    "#             d[key] = value\n",
    "#     return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add complexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"Complex\"\n",
    "q = '''MATCH (n:%s) RETURN DISTINCT n.name'''%label\n",
    "already_defined_complexes = set([d['n.name'] for d in graph.run(q).data()])\n",
    "already_defined_complexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complexes_to_add = set(pd.read_csv(parsed_path / \"complexes_to_add.tsv\", sep=\"\\t\", header=None)[0]) - set(already_defined_complexes)\n",
    "len(complexes_to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_w_new_complex = get_x_nodes(df_edges, complexes_to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "want_cols = ['reaction_type', 'Modifications', 'Species']\n",
    "for prefix in ['input1', 'input2', 'input3', 'output1']:\n",
    "    want_cols += [f\"{prefix}_{x}\" for x in ['newID', 'location', 'label', 'form']]\n",
    "\n",
    "df_new_complex = df_edges.loc[rows_w_new_complex, want_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first complexes defined by binding/oglimerisation reactions\n",
    "key = 'binding/oligomerisation'\n",
    "subdf = df_new_complex.loc[df_new_complex['reaction_type'] == key]\n",
    "\n",
    "binding_w_catalyst = subdf.loc[subdf['Modifications'] == 'with catalyst']\n",
    "binding_wo_catalyst = subdf.loc[subdf['Modifications'] != 'with catalyst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdf_wo_catalyst = number_input_different(binding_wo_catalyst, homologues=False)\n",
    "subdf_w_catalyst = number_input_different(binding_w_catalyst, homologues=False, catalyst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdf_wo_catalyst = subdf_wo_catalyst[['substrate_name', 'substrate_label', 'substrate_form', 'output1_newID', 'product_name']]\n",
    "subdf_w_catalyst = subdf_w_catalyst[['substrate_name', 'substrate_label', 'substrate_form', 'output1_newID', 'product_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_subdf = pd.concat([subdf_wo_catalyst, subdf_w_catalyst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_subdf.drop_duplicates('product_name', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_subdf['substrate_label'] = new_subdf['substrate_label'].apply(lambda x: [z + \":FunctionalCluster\" if (z in helpers.plant_node_labels) else z  for z in x ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_subdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binding_defined_complexes = set(new_subdf['product_name'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(binding_defined_complexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other complexes\n",
    "other_complexes_set = set()\n",
    "for i , row in df_new_complex.iterrows():\n",
    "    for col_prefix in ['input1', 'input2', 'input3', 'output1']:\n",
    "        if row[col_prefix + \"_label\"] == 'Complex':\n",
    "            c = row[col_prefix + \"_newID\"]\n",
    "            if not ((c in binding_defined_complexes) or (c in already_defined_complexes)):\n",
    "                other_complexes_set.add((row['Species'], row[col_prefix + \"_newID\"]))\n",
    "print(other_complexes_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subunits(x):\n",
    "    if '|' in x:\n",
    "        return x.split('|')\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_label(x):\n",
    "    ids_ = x['substrate_og_name']\n",
    "    species = x['species']\n",
    "    species = ','.join(species.split('/'))\n",
    "    names = []\n",
    "    labels = []\n",
    "    levels_ = ['node', 'clade', 'family']\n",
    "    for id_ in ids_:\n",
    "        functional_cluster = None\n",
    "        label = None\n",
    "        for level_ in levels_:\n",
    "            try: \n",
    "                functional_cluster = translate_functional_clusters.loc[(id_, level_, species)]['functional_cluster_name']\n",
    "                label = translate_functional_clusters.loc[(id_, level_, species)]['labels']\n",
    "                #print(id_, level_, functional_cluster, label)\n",
    "            except:\n",
    "                #print(id_, level_)\n",
    "                pass\n",
    "\n",
    "        #display(functional_cluster)\n",
    "        if functional_cluster:\n",
    "            label = \"FunctionalCluster:\" + label\n",
    "        else:\n",
    "            functional_cluster, label = node_id_to_node(id_)\n",
    "        if not functional_cluster:\n",
    "            print(\"ERROR: cannot identify correct subunit:\", id_, level_)\n",
    "\n",
    "            \n",
    "        names.append(functional_cluster)\n",
    "        labels.append(label)\n",
    "    return names, labels\n",
    "\n",
    "\n",
    "def clean_labels(labels):\n",
    "\tfor x in ['Family', 'Plant', 'Foreign', 'Node']:\n",
    "\t\tif x in labels:\n",
    "\t\t\tlabels.remove(x)\n",
    "\treturn labels[0]\n",
    "\n",
    "def node_id_to_node(id_):\n",
    "\n",
    "    query = '''MATCH (s) WHERE s.name=$x \n",
    "               RETURN s.name AS name, labels(s) AS labels'''\n",
    "    \n",
    "    cursor = graph.run(query, x=id_)\n",
    "    d = cursor.data()\n",
    "    \n",
    "    if len(d) == 0:\n",
    "        print(id_, d, \"no hit\")\n",
    "        return None, None\n",
    "    elif len(d) == 1:\n",
    "        label = clean_labels(d[0]['labels'])\n",
    "        name = d[0]['name']\n",
    "        return name, label\n",
    "    else:\n",
    "        print(id_, d, 'multiple hits') # should be impossible\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_complexes = pd.DataFrame(other_complexes_set, columns=['species', 'output1_newID'])\n",
    "other_complexes['substrate_og_name'] = other_complexes['output1_newID'].apply(get_subunits)\n",
    "other_complexes['substrate_form'] = other_complexes['substrate_og_name'].apply(lambda x: [\"\" for c in x])\n",
    "other_complexes['product_name'] = other_complexes['output1_newID']\n",
    "other_complexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_complexes[['substrate_name', 'substrate_label']] = other_complexes[['species', 'substrate_og_name']].apply(get_name_label, axis=1, result_type='expand')\n",
    "other_complexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del other_complexes['substrate_og_name']\n",
    "del other_complexes['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_complexes = other_complexes.append(new_subdf, sort=True).reset_index(drop=True)\n",
    "new_complexes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_new_subdf = helpers.unnesting(new_complexes, ['substrate_name', 'substrate_label', 'substrate_form']).drop_duplicates()\n",
    "exploded_new_subdf[exploded_new_subdf['product_name']=='NPR1|PAD4|TGA2,5,6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save new complexes \n",
    "label = 'Complex'\n",
    "f = f'{label}-new-components.tsv'\n",
    "want_cols = 'product_name'\n",
    "new_complexes[want_cols].to_csv(f'../data/import/{f}', sep=\"\\t\", index=None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_complexes.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = helpers.bioelement_node_query(f, \"Complex\", \n",
    "                           n_name=\"line.product_name\")\n",
    "#print(query)\n",
    "qr = graph.run(query)\n",
    "if not new_complexes.shape[0] == qr.stats()['nodes_created']:\n",
    "     raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_new_subdf[exploded_new_subdf['product_name']=='D14|MAX2|SCF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_new_subdf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# component to complex edges\n",
    "edge_type = 'COMPONENT_OF'\n",
    "want_cols = ['substrate_name', 'substrate_form', 'substrate_label', 'product_name']\n",
    "\n",
    "for t, this_subdf in exploded_new_subdf.groupby(\"substrate_label\"):\n",
    "    f = f'{edge_type}-{label}-{t}-edges.tsv'  \n",
    "    print(t, this_subdf.shape[0])\n",
    "    this_subdf[want_cols].to_csv(f\"../data/import/{f}\", index=None, sep=\"\\t\")\n",
    "\n",
    "    query = helpers.make_create_type_of_edge_query(f, edge_type,\n",
    "                           source_label=t, target_label=\"Complex\",\n",
    "                           source_name=\"line.substrate_name\", target_name=\"line.product_name\",\n",
    "                           #source_form=\"line.substrate_form\"\n",
    "                          )\n",
    "    print(query)\n",
    "    qr = graph.run(query)\n",
    "    \n",
    "    r_created = qr.stats()['relationships_created']\n",
    "    print(t, this_subdf.shape[0], r_created)    \n",
    "    if not this_subdf.shape[0] == r_created:\n",
    "        print(\"\\tnot all edges created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
