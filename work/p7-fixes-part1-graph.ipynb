{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"v0.1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import neo4j DB: 7/?\n",
    "\n",
    "Code to translate v2.7.9_PIS-model.xlsx to neo4j database. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph, Node, Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to graph via docker-compose link. See http://localhost:7474/browser/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph(host=\"neo4j\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "base_path = Path(\"..\")\n",
    "parsed_path = base_path / \"data\" / \"parsed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MK identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXED in sheet\n",
    "# cy = \"\"\"\n",
    "#     MATCH p=(r {name:\"rx00308\"})--(n {family:\"MYB\"})\n",
    "#     SET n.name = 'MYB33[Sotub06g030530.1.1]'\n",
    "#     SET n.stu_homolugues = ['Sotub06g030530.1.1']\n",
    "#     SET n._identifiers = 'Sotub06g030530.1.1'\n",
    "# \"\"\"\n",
    "# graph.run(cy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cy = \"\"\"\n",
    "    MATCH p=(r {name:\"rx00308\"})--(n {family:\"MYB\"})\n",
    "    RETURN n\n",
    "\"\"\"\n",
    "\n",
    "graph.run(cy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(base_path / \"data\" / \"raw\" / \"pss-pathways - neo4j-for-CB.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df[\"pathway\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df[\"node_type\"].apply(lambda x: \":\".join(eval(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, subdf in df.groupby(\"label\"):\n",
    "    f = f\"pathways-{label}.tsv\"\n",
    "    subdf.to_csv(base_path / \"data\" / \"import\" / f, sep=\"\\t\", index=None)\n",
    "    cy = '''\n",
    "    LOAD CSV WITH HEADERS FROM  'file:///{file}' AS line FIELDTERMINATOR '\\t'\n",
    "           MATCH (n:{label}  {{ name:line.name}})\n",
    "           SET n.pathway = line.pathway\n",
    "           RETURN n.name, n.pathway, line.pathway\n",
    "    '''.format(label=label, file=f)\n",
    "#     print(cy)\n",
    "    qr = graph.run(cy)\n",
    "#     print(qr)\n",
    "    print(label, \"\\t\\t\\t\", len(qr.data())==subdf.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add species to reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges = pd.read_csv(parsed_path / \"edges-sheet.tsv\", sep=\"\\t\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"reaction_species.tsv\"\n",
    "df_edges[['reaction_id', 'species']].to_csv(base_path / \"data\" / \"import\" / f, sep=\"\\t\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(df_edges['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cy = '''\n",
    "LOAD CSV WITH HEADERS FROM  'file:///{file}' AS line FIELDTERMINATOR '\\t'\n",
    "       MATCH (n:{label}  {{ name:line.reaction_id}})\n",
    "       SET n.species = split(line.species, ',')\n",
    "       RETURN n.name, n.species, line.species\n",
    "'''.format(label=\"Reaction\", file=f)\n",
    "\n",
    "graph.run(cy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FunctionalCluster annotations from Ziva file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metabolites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path / \"data\" /\"raw\" / \"gmmmeta_20211011.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(base_path / \"data\" /\"raw\" / \"GMM\" / \"gmmmeta_20211011.tsv\", sep=\"\\t\", header=None, \n",
    "                 usecols=[2, 8],\n",
    "                names=[\"name\", \"chebi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df[\"chebi\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"chebi\"] = df[\"chebi\"].apply(lambda x: ','.join([s.strip().lower() for s in x.split(\"|\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"gmm_annot_Metabolite.tsv\"\n",
    "df.to_csv(base_path / \"data\" / \"import\" / f, sep=\"\\t\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cy = '''\n",
    "LOAD CSV WITH HEADERS FROM  'file:///{file}' AS line FIELDTERMINATOR '\\t'\n",
    "       MATCH (n:{label})\n",
    "       WHERE n.description =~ \"(?i)\"+line.name\n",
    "       OR n.name =~ \"(?i)\"+line.name\n",
    "       WITH  n.external_links + split(line.chebi, \",\") as new, n, line\n",
    "       SET n.external_links = apoc.coll.toSet(new)\n",
    "       RETURN n.name, n.external_links\n",
    "'''.format(label=\"Metabolite\", file=f)\n",
    "#     print(cy)\n",
    "qr = graph.run(cy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### srna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(base_path / \"data\" /\"raw\" / \"GMM\" / \"gmmsrna_20211011.tsv\", sep=\"\\t\", header=None, \n",
    "                 #usecols=[2, 8],\n",
    "                #names=[\"name\", \"chebi\"]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df.columns:\n",
    "    print(c)\n",
    "    display(df[c].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.empty_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(base_path / \"data\" /\"raw\" / \"GMM\" / \"gmmprot_20211011.tsv\", sep=\"\\t\", header=None, \n",
    "                 usecols=[2, 4, 7, 8], \n",
    "                 names=[\"identifier\", \"description\", \"short_name\", \"synonyms\"], \n",
    "                 na_values=helpers.empty_strings, \n",
    "                 converters={\"synonyms\": lambda x: '' if x =='NULL' else ','.join([s.strip() for s in x.split(\"|\")])}\n",
    "                )\n",
    "for c in df1.columns:\n",
    "    df1[c] = df1[c].str.strip()\n",
    "df1.fillna('', inplace=True)\n",
    "df1.set_index(\"identifier\", inplace=True)\n",
    "\n",
    "\n",
    "df1.columns = [\"gmm_description1\", \"short_name\", \"synonyms\"]\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_excel(base_path / \"data\" /\"raw\" / \"v2.7.9_PIS-model.xlsx\", \n",
    "                    sheet_name=\"defGMM\", \n",
    "                    header=[0], \n",
    "                    dtype=str, \n",
    "                    usecols=[0, 1, 2, 3, 4, 5],\n",
    "                    converters={\"GMM:Synonyms\": lambda x: '' if x =='NULL' else ','.join([s.strip() for s in x.split(\"|\")])}\n",
    ")\n",
    "for c in df2.columns:\n",
    "    df2[c] = df2[c].str.strip()\n",
    "df2.fillna('', inplace=True)\n",
    "df2.set_index(\"GeneID\", inplace=True)\n",
    "\n",
    "df2.columns = ['gmm_ocd_all', 'gmm_ocd_plaza', 'gmm_description', 'GMM:ShortName',\n",
    "       'GMM:Synonyms']\n",
    "\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_excel(base_path / \"data\" /\"raw\" / \"v2.7.9_PIS-model.xlsx\", \n",
    "                    sheet_name=\"Components\", \n",
    "                    header=[1], \n",
    "                    dtype=str, \n",
    "                    na_values=helpers.empty_strings,\n",
    "                    usecols=[4, 7, 8, 9, 11, 12],\n",
    ")\n",
    "for c in df3.columns:\n",
    "    df3[c] = df3[c].str.strip()\n",
    "df3.fillna('', inplace=True)\n",
    "\n",
    "df3 = df3[df3['NodeType']=='plant_coding']\n",
    "\n",
    "df3[\"GMM:Synonyms\"] = df3[\"GMM:Synonyms\"].apply(lambda x: '' if x =='NULL' else ','.join([s.strip() for s in x.split(\"|\")]))\n",
    "\n",
    "df3 = df3[[\"NodeID\", \"NodeName\",  \"GMM:Synonyms\", \"NodeDescription\", \"AdditionalInfo\"]]\n",
    "df3.columns = [\"NodeID\", \"pis_shortname\", \"pis_synonyms\", \"pis_description\",  \"additional_information\"]\n",
    "\n",
    "df3.set_index(\"NodeID\", inplace=True)\n",
    "\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.join(df2, how='outer').join(df3, how='outer')\n",
    "df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['AT3G63110']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gmm_description_one(x):\n",
    "    zd = x[\"gmm_description1\"] #ziva file\n",
    "    fd = x[\"gmm_description\"]  #xtra sheet in PIS\n",
    "    \n",
    "    if zd != '':\n",
    "        return zd\n",
    "    else:\n",
    "        return fd\n",
    "\n",
    "\n",
    "\n",
    "df[\"new_gmm_description\"] = df[[\"gmm_description1\", \"gmm_description\", \"pis_description\"]].apply(get_gmm_description_one, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_description_one(x):\n",
    "    zd = x[\"gmm_description1\"] #ziva file\n",
    "    fd = x[\"gmm_description\"]  #xtra sheet in PIS\n",
    "    lr = x[\"pis_description\"]  #pis NodeDescription\n",
    "    \n",
    "    if lr != '':\n",
    "        return lr\n",
    "    elif fd != '':\n",
    "        return fd\n",
    "    else:\n",
    "        return zd\n",
    "\n",
    "\n",
    "df[\"new_description\"] = df[[\"gmm_description1\", \"gmm_description\", \"pis_description\"]].apply(get_description_one, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set(x):\n",
    "    zd = x[\"synonyms\"]\n",
    "    fd = x[\"GMM:Synonyms\"]\n",
    "    lr = x[\"pis_synonyms\"]\n",
    "\n",
    "    s = set(zd.split(\",\") + fd.split(\",\") + lr.split(\",\") + [x[\"pis_shortname\"], x[\"short_name\"]])\n",
    "    s.discard('')\n",
    "    \n",
    "    return ','.join(list(s))\n",
    "\n",
    "df[\"new_synonyms\"] = df[[\"pis_shortname\", \"short_name\", \"synonyms\", \"GMM:Synonyms\", \"pis_synonyms\"]].apply(get_set, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"new_description\", \"new_gmm_description\", \"new_synonyms\", \"additional_information\"]]\n",
    "df.columns = [\"description\", \"gmm_description\", \"synonyms\", \"additional_information\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['AT5G38450']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Os11g0104300']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['LOC_Os02g36974']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cy = \"\"\"\n",
    "    MATCH (n:FunctionalCluster)\n",
    "    WHERE size(n.ath_homologues) = 1\n",
    "    AND \"AT3G03990\" IN n.ath_homologues\n",
    "    RETURN n, size(n.ath_homologues)\n",
    "\"\"\"\n",
    "\n",
    "qr = graph.run(cy)\n",
    "qr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cy = \"\"\"\n",
    "    MATCH (n:FunctionalCluster:PlantCoding)\n",
    "    WHERE size(n.ath_homologues) = 1\n",
    "    AND n.sly_homologues IS NULL\n",
    "    AND n.stu_homologues IS NULL\n",
    "    AND n.osa_homologues IS NULL\n",
    "    RETURN count(*)\n",
    "\"\"\"\n",
    "\n",
    "qr = graph.run(cy)\n",
    "qr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cy = \"\"\"\n",
    "    MATCH (n:FunctionalCluster:PlantCoding)\n",
    "    WHERE size(n.sly_homologues) = 1\n",
    "    AND n.ath_homologues IS NULL\n",
    "    AND n.stu_homologues IS NULL\n",
    "    AND n.osa_homologues IS NULL    \n",
    "    RETURN count(*)\n",
    "\"\"\"\n",
    "\n",
    "qr = graph.run(cy)\n",
    "qr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cy = \"\"\"\n",
    "    MATCH (n:FunctionalCluster:PlantCoding)\n",
    "    WHERE size(n.stu_homologues) = 1\n",
    "    AND n.sly_homologues IS NULL\n",
    "    AND n.ath_homologues IS NULL\n",
    "    AND n.osa_homologues IS NULL    \n",
    "    RETURN count(*)\n",
    "\"\"\"\n",
    "\n",
    "qr = graph.run(cy)\n",
    "qr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cy = \"\"\"\n",
    "    MATCH (n:FunctionalCluster:PlantCoding)\n",
    "    WHERE size(n.osa_homologues) = 1\n",
    "    AND n.sly_homologues IS NULL\n",
    "    AND n.stu_homologues IS NULL\n",
    "    AND n.ath_homologues IS NULL    \n",
    "    RETURN count(*)\n",
    "\"\"\"\n",
    "\n",
    "qr = graph.run(cy)\n",
    "qr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.name = 'identifier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_species = {}\n",
    "for species, prefix in [\n",
    "    ('ath', \"AT\"),\n",
    "    #('osa', ), os in table are LOC_Os????\n",
    "    ('sly', \"Soly\"), \n",
    "    ('stu', 'Sotub', )\n",
    "     ]:\n",
    "    tdf = df[df.index.str.startswith(prefix)]\n",
    "    print(species, tdf.shape[0])\n",
    "    f = f\"gmm_annot_Prot-{species}.tsv\"\n",
    "    tdf.reset_index().to_csv(base_path / \"data\" / \"import\" / f, sep=\"\\t\", index=None)\n",
    "    per_species[species]  = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_found['new_synonyms'] = x_found['n.name'].apply(lambda x : x.split(\"[\")[0])\n",
    "def get_synonyms(x):\n",
    "    synonyms = [x['short_name']]\n",
    "\n",
    "    if x['line.short_name']:\n",
    "        synonyms.append(x['line.short_name'])\n",
    "    \n",
    "    if x['line.synonyms']:\n",
    "        synonyms += x['line.synonyms'].split(',')\n",
    "    \n",
    "    synonyms = [x.strip().upper() for x in synonyms]\n",
    "    \n",
    "    synonyms = set(synonyms)\n",
    "    synonyms.discard('')\n",
    "    \n",
    "    return ','.join(sorted(list(synonyms)))\n",
    "    \n",
    "def combine_exists_and_found(species):\n",
    "    f = per_species[species]\n",
    "\n",
    "    s_exc = ''\n",
    "    for sp2 in [\"ath\", \"osa\", \"sly\", \"stu\"]:\n",
    "        if sp2 != species:\n",
    "            s_exc += f\"AND n.{sp2}_homologues IS NULL\\n\"\n",
    "    \n",
    "    \n",
    "    cy = '''\n",
    "    LOAD CSV WITH HEADERS FROM  'file:///{file}' AS line FIELDTERMINATOR '\\t'\n",
    "           MATCH (n:{label})\n",
    "           WHERE size(n.{species}_homologues) = 1\n",
    "           {s_exc}\n",
    "           AND ANY ( item IN n.{species}_homologues WHERE item =~ \"(?i)\" + line.identifier )\n",
    "           RETURN n.name, line.short_name, n.description, line.description, n.synonyms, line.synonyms, line.gmm_description \n",
    "    '''.format(label=\"FunctionalCluster\", file=f, species=species, s_exc=s_exc)\n",
    "    print(cy)\n",
    "    qr = graph.run(cy)    \n",
    "    x_found = pd.DataFrame(qr.data())\n",
    "    print(len(x_found))\n",
    "    \n",
    "    x_found['short_name'] = x_found['n.name'].apply(lambda x : x.split(\"[\")[0])\n",
    "    x_found['synonyms'] = x_found[['line.short_name', 'line.synonyms', 'short_name']].apply(get_synonyms, axis=1)\n",
    "\n",
    "    x_found['name'] = x_found['n.name']\n",
    "    x_found['description'] = x_found['line.description']\n",
    "    x_found['gmm_description'] = x_found['line.gmm_description']\n",
    "\n",
    "    \n",
    "    x_found = x_found[['name', 'short_name', 'synonyms', 'description', 'gmm_description']]\n",
    "    \n",
    "    return x_found\n",
    "\n",
    "def add_properties(species, df):\n",
    "    f = f\"gmm_annot_Prot-{species}-combined.tsv\"\n",
    "\n",
    "    df.to_csv(base_path / \"data\" / \"import\" / f, sep=\"\\t\", index=None)\n",
    "    \n",
    "    cy = '''\n",
    "    LOAD CSV WITH HEADERS FROM  'file:///{file}' AS line FIELDTERMINATOR '\\t'\n",
    "           MATCH (n:{label} {{name:line.name}})\n",
    "           SET n.short_name = line.short_name\n",
    "           SET n.synonyms = split(line.synonyms, ',')\n",
    "           SET n.description = line.description\n",
    "           SET n.gmm_description = line.gmm_description\n",
    "           RETURN n.name \n",
    "    '''.format(label=\"FunctionalCluster\", file=f, species=species, s_exc=s_exc)\n",
    "    print(cy)\n",
    "    qr = graph.run(cy)    \n",
    "    \n",
    "    return qr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_found = combine_exists_and_found(\"ath\")\n",
    "qr = add_properties('ath', x_found)\n",
    "print(len(qr.data()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cy = \"\"\"\n",
    "    MATCH (n:FunctionalCluster:PlantCoding)\n",
    "    WHERE size(n.stu_homologues) = 1\n",
    "    AND n.sly_homologues IS NULL\n",
    "    AND n.ath_homologues IS NULL\n",
    "    AND n.osa_homologues IS NULL    \n",
    "    RETURN n.name\n",
    "\"\"\"\n",
    "\n",
    "qr = graph.run(cy)\n",
    "qr.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_found = combine_exists_and_found(\"stu\")\n",
    "qr = add_properties('stu', x_found)\n",
    "print(len(qr.data()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_found = combine_exists_and_found(\"sly\")\n",
    "# #qr = add_properties('sly', x_found)\n",
    "# #print(len(qr.data()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cy = \"\"\"\n",
    "    MATCH (n:FunctionalCluster)\n",
    "    WHERE n.stu_homologues IS NULL\n",
    "    AND n.sly_homologues IS NULL\n",
    "    AND n.ath_homologues IS NULL\n",
    "    AND n.osa_homologues IS NULL    \n",
    "    RETURN n.name\n",
    "\"\"\"\n",
    "\n",
    "qr = graph.run(cy)\n",
    "qr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(qr.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['short_name'] = df['n.name'].apply(lambda x : x.split(\"[\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"name\", \"short_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = f\"gmm_annot_Prot-{species}-nonname.tsv\"\n",
    "\n",
    "df.to_csv(base_path / \"data\" / \"import\" / f, sep=\"\\t\", index=None)\n",
    "\n",
    "cy = '''\n",
    "LOAD CSV WITH HEADERS FROM  'file:///{file}' AS line FIELDTERMINATOR '\\t'\n",
    "       MATCH (n:{label} {{name:line.name}})\n",
    "       SET n.short_name = line.short_name\n",
    "       RETURN n.name \n",
    "'''.format(label=\"FunctionalCluster\", file=f)\n",
    "print(cy)\n",
    "qr = graph.run(cy)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
